### 如何决定使用 HashMap 还是 TreeMap？

对于在Map中插入、删除和定位元素这类操作，HashMap是最好的选择。然而，假如你需要对一个有序的key集合进行遍历，TreeMap是更好的选择。基于你的collection的大小，也许向HashMap中添加元素会更快，将map换为TreeMap进行有序key的遍历。



### 说一下 HashMap 的实现原理？

HashMap概述： HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。

HashMap的数据结构： 在Java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。

HashMap 基于 Hash 算法实现的

1. 当我们往Hashmap中put元素时，利用key的hashCode重新hash计算出当前对象的元素在数组中的下标
2. 存储时，如果出现hash值相同的key，此时有两种情况。(1)如果key相同，则覆盖原始值；(2)如果key不同（出现冲突），则将当前的key-value放入链表中
3. 获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值。
4. 理解了以上过程就不难明白HashMap是如何解决hash冲突的问题，核心就是使用了数组的存储方式，然后将冲突的key的对象放入链表中，一旦发现冲突就在链表中做进一步的对比。

需要注意Jdk 1.8中对HashMap的实现做了优化，当链表中的节点数据超过八个之后，该链表会转为红黑树来提高查询效率，从原来的O(n)到O(logn)



### JDK1.8主要解决或优化了一下问题：

1. resize 扩容优化
2. 引入了红黑树，目的是避免单条链表过长而影响查询效率，红黑树算法请参考
3. 解决了多线程死循环问题，但仍是非线程安全的，多线程时可能会造成数据丢失问题。

| 不同                     | JDK 1.7                                                      | JDK 1.8                                                      |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储结构                 | 数组 + 链表                                                  | 数组 + 链表 + 红黑树                                         |
| 初始化方式               | 单独函数：`inflateTable()`                                   | 直接集成到了扩容函数`resize()`中                             |
| hash值计算方式           | 扰动处理 = 9次扰动 = 4次位运算 + 5次异或运算                 | 扰动处理 = 2次扰动 = 1次位运算 + 1次异或运算                 |
| 存放数据的规则           | 无冲突时，存放数组；冲突时，存放链表                         | 无冲突时，存放数组；冲突 & 链表长度 < 8：存放单链表；冲突 & 链表长度 > 8：树化并存放红黑树 |
| 插入数据方式             | 头插法（先讲原位置的数据移到后1位，再插入数据到该位置）      | 尾插法（直接插入到链表尾部/红黑树）                          |
| 扩容后存储位置的计算方式 | 全部按照原来方法进行计算（即hashCode ->> 扰动函数 ->> (h&length-1)） | 按照扩容后的规律计算（即扩容后的位置=原位置 or 原位置 + 旧容量） |



### HashMap是怎么解决哈希冲突的？

答：在解决这个问题之前，我们首先需要知道**什么是哈希冲突**，而在了解哈希冲突之前我们还要知道**什么是哈希**才行；

#### 什么是哈希？

Hash，一般翻译为“散列”，也有直接音译为“哈希”的，这就是把任意长度的输入通过散列算法，变换成固定长度的输出，该输出就是散列值（哈希值）；这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。

所有散列函数都有如下一个基本特性：根据同一散列函数计算出的散列值如果不同，那么输入值肯定也不同。但是，根据同一散列函数计算出的散列值如果相同，输入值不一定相同。

#### 什么是哈希冲突？

当两个不同的输入值，根据同一散列函数计算出相同的散列值的现象，我们就把它叫做碰撞（哈希碰撞）

简单总结一下HashMap是使用了哪些方法来有效解决哈希冲突的：

**1. 使用链地址法（使用散列表）来链接拥有相同hash值的数据；**
**2. 使用2次扰动函数（hash函数）来降低哈希冲突的概率，使得数据分布更平均；**
**3. 引入红黑树进一步降低遍历的时间复杂度，使得遍历更快；**





### 能否使用任何类作为 Map 的 key？

可以使用任何类作为 Map 的 key，然而在使用之前，需要考虑以下几点：

- 如果类重写了 equals() 方法，也应该重写 hashCode() 方法。
- 类的所有实例需要遵循与 equals() 和 hashCode() 相关的规则。
- 如果一个类没有使用 equals()，不应该在 hashCode() 中使用它。
- 用户自定义 Key 类最佳实践是使之为不可变的，这样 hashCode() 值可以被缓存起来，拥有更好的性能。不可变的类也可以确保 hashCode() 和 equals() 在未来不会改变，这样就会解决与可变相关的问题了。

### 为什么HashMap中String、Integer这样的包装类适合作为Key？

答：String、Integer等包装类的特性能够保证Hash值的不可更改性和计算准确性，能够有效的减少Hash碰撞的几率

1. 都是final类型，即不可变性，保证key的不可更改性，不会存在获取hash值不同的情况
2. 内部已重写了`equals()`、`hashCode()`等方法，遵守了HashMap内部的规范（不清楚可以去上面看看putValue的过程），不容易出现Hash值计算错误的情况；

### 如果使用Object作为HashMap的Key，应该怎么办呢？

答：重写`hashCode()`和`equals()`方法

1. **重写`hashCode()`是因为需要计算存储数据的存储位置**，需要注意不要试图从散列码计算中排除掉一个对象的关键部分来提高性能，这样虽然能更快但可能会导致更多的Hash碰撞；
2. **重写`equals()`方法**，需要遵守自反性、对称性、传递性、一致性以及对于任何非null的引用值x，x.equals(null)必须返回false的这几个特性，**目的是为了保证key在哈希表中的唯一性**；



### HashMap 与 HashTable 有什么区别？

1. **线程安全**： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过 `synchronized` 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）；
2. **效率**： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它；
3. **对Null key 和Null value的支持**： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛NullPointerException。
4. **初始容量大小和每次扩充容量大小的不同 **： ①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小。也就是说 HashMap 总是使用2的幂作为哈希表的大小，后面会介绍到为什么是2的幂次方。
5. **底层数据结构**： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。(将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。)Hashtable 没有这样的机制。
6. 推荐使用：在 Hashtable 的类注释可以看到，Hashtable 是保留类不建议使用，推荐在单线程环境下使用 HashMap 替代，如果需要多线程使用则用 ConcurrentHashMap 替代。

### HashMap 和 ConcurrentHashMap 的区别

1. ConcurrentHashMap对整个桶数组进行了分割分段(Segment)，然后在每一个分段上都用lock锁进行保护，相对于HashTable的synchronized锁的粒度更精细了一些，并发性能更好，而HashMap没有锁机制，不是线程安全的。（JDK1.8之后ConcurrentHashMap启用了一种全新的方式实现,利用CAS算法。）
2. HashMap的键值对允许有null，但是ConCurrentHashMap都不允许。'



### 如何决定使用 HashMap 还是 TreeMap？

对于在Map中插入、删除和定位元素这类操作，HashMap是最好的选择。然而，假如你需要对一个有序的key集合进行遍历，TreeMap是更好的选择。基于你的collection的大小，也许向HashMap中添加元素会更快，将map换为TreeMap进行有序key的遍历。



# 1. HashMap总览

## 1.1 hashmap底层储存结构图解

底层结构其实就是数组+链表+红黑树

<img src="https://gitee.com/gu_chun_bo/picture/raw/master/image/20201003110314-282089.png" alt="1601357648567" style="zoom: 67%;" />





## 1.2 HashMap类定义

先来看看HashMap的定义：

```java
public class HashMap<K,V> extends AbstractMap<K,V>    implements Map<K,V>, Cloneable, Serializable {}
```

从中我们可以了解到：

- `HashMap<K,V>`：`HashMap`是以`key-value`形式存储数据的。
- `extends AbstractMap<K,V>`：继承了`AbstractMap`，大大减少了实现Map接口时需要的工作量。
- `implements Map<K,V>`：实现了`Map`，提供了所有可选的`Map`操作。
- `implements Cloneable`：表明其可以调用`clone()`方法来返回实例的`field-for-field`拷贝。
- `implements Serializable`：表明该类是可以序列化的。

![1601693853158](https://gitee.com/gu_chun_bo/picture/raw/master/image/20201003105734-514068.png)



## 1.3 put()数据原理分析图解

![1601357215805](https://gitee.com/gu_chun_bo/picture/raw/master/image/20200929132656-232566.png)

**.put方法运行之后,先获取到对应key的hash值,根据路由寻址公式的算法寻找到该值应该存放的位置, 如果路由寻址公式计算的结果在数组中已经出现,就把需要添加的数据放入到相同位置之后,数组位置形成了一个链表**

## 1.4 一些名词

1. **hashmap的底层数据结构名为table的数组，是一个Node数组**
2. **table数组中的每个元素是一个Node元素（但是这个Node元素可能指向下一个Node元素从而形成链表），table数组的每个位置称为桶，比如talbe[0] 称为一个桶，也可以称为一个bin**



# 2. 源码

## 2.1 核心属性分析

**DEFAULT_INITIAL_CAPACITY = 1 << 4**; // aka 16:默认的数组的初始容量，必须是二的次方

**MAXIMUM_CAPACITY = 1 << 30**  : 最大容量，当通过构造函数隐式指定了一个大于MAXIMUM_CAPACITY的时候使用:MAXIMUM_CAPACITY = 1 << 30

**DEFAULT_LOAD_FACTOR = 0.75f**: 加载因子，当构造函数没有指定加载因子的时候的默认值的时候使用

**TREEIFY_THRESHOLD = 8**:TREEIFY_THRESHOLD为当一个bin从list转化为tree的阈值，当一个bin中元素的总元素最低超过这个值的时候，bin才被转化为tree；为了满足转化为简单bin时的要求，TREEIFY_THRESHOLD必须比2大而且比8要小

**UNTREEIFY_THRESHOLD = 6**:bin反tree化时的最大值，应该比TREEIFY_THRESHOLD要小，为了在移除元素的时候能检测到移除动作，UNTREEIFY_THRESHOLD必须至少为6

**MIN_TREEIFY_CAPACITY = 64**:树化的另外一个阈值，table的长度(注意不是bin的长度)的最小得为64。为了避免扩容和树型结构化阈值之间的冲突，MIN_TREEIFY_CAPACITY 应该最小是 4 * TREEIFY_THRESHOLD

### 静态常量

```java
    /**
     * The default initial capacity - MUST be a power of two.
     * 默认的初始容量，必须是二的次方
     */
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

    /**
     * 最大容量，当通过构造函数隐式指定了一个大于MAXIMUM_CAPACITY的时候使用
     */
    static final int MAXIMUM_CAPACITY = 1 << 30;

    /**
     * The load factor used when none specified in constructor.
     * 加载因子，当构造函数没有指定加载因子的时候的默认值的时候使用
     */
    static final float DEFAULT_LOAD_FACTOR = 0.75f;

    /**
     * 
     * TREEIFY_THRESHOLD为当一个bin从list转化为tree的阈值，当一个bin中元素的总元素最低超过这个值的时候，bin才被转化为tree；
     * 为了满足转化为简单bin时的要求，TREEIFY_THRESHOLD必须比2大而且比8要小
     */
    static final int TREEIFY_THRESHOLD = 8;

    /**
     * 
     * bin反tree化时的最大值，应该比TREEIFY_THRESHOLD要小，
     * 为了在移除元素的时候能检测到移除动作，UNTREEIFY_THRESHOLD必须至少为6
     */
    static final int UNTREEIFY_THRESHOLD = 6;

    /**
     * 树化的另外一个阈值，table的长度(注意不是bin的长度)的最小得为64。为了避免扩容和树型结构化阈值之间的冲突，MIN_TREEIFY_CAPACITY 应该最小是 4 * TREEIFY_THRESHOLD
     */
    static final int MIN_TREEIFY_CAPACITY = 64;
   
  
```

### 成员变量

```java
 	/**
     * 
     * table，第一次被使用的时候才进行加载
     */
    transient Node<K,V>[] table;

    /**
     * Holds cached entrySet(). Note that AbstractMap fields are used
     * for keySet() and values().
     * 键值对缓存，它们的映射关系集合保存在entrySet中。即使Key在外部修改导致hashCode变化，缓存中还可以找到映射关系
     */
    transient Set<Map.Entry<K,V>> entrySet;

    /**
     * The number of key-value mappings contained in this map.
     * table中 key-value 元素的个数
     */
    transient int size;

    /**
     * 
     * HashMap在结构上被修改的次数，结构上被修改是指那些改变HashMap中映射的数量或者以其他方式修改其内部结构的次数（例如，rehash）。
     * 此字段用于使HashMap集合视图上的迭代器快速失败。
     */
    transient int modCount;

    /**
     *
     * 下一次resize扩容阈值，当前table中的元素超过此值时，触发扩容
     * threshold = capacity * load factor  //load factor 默认为0.75 
     * @serial
     */
    int threshold;

    /**
     * The load factor for the hash table.
     * 负载因子
     * @serial
     */
    final float loadFactor;

```

### 节点类型

```java
    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;//哈希值
        final K key;//key
        V value;//value
        Node<K,V> next;//链表后置节点

        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }
        public final K getKey()        { return key; }
        public final V getValue()      { return value; }
        public final String toString() { return key + "=" + value; }
    }

```







## 2.2 构造方法分析

仅仅看最长参数的构造方法就行了，其它三个都是调用了此构造方法：

```java
    public HashMap(int initialCapacity, float loadFactor) {
        //其实就是做了一些校验
        if (initialCapacity < 0)
            throw new IllegalArgumentException("Illegal initial capacity: " +
                    initialCapacity);
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        
        //loadFactor 也必须大于0
        if (loadFactor <= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException("Illegal load factor: " +
                    loadFactor);
        this.loadFactor = loadFactor;
        this.threshold = tableSizeFor(initialCapacity);
    }

    /**
     * Returns a power of two size for the given target capacity.
     * 
     * 1.返回一个大于等于当前值cap的一个的数字，并且这个数字一定是2的次方数
     * 假如cap为10，那么n= 9 = 0b1001 //9转换为2进制
     * 0b1001 | 0b0100 = 0b1101
     * 0b1101 | 0b0011 = 0b1111
     * 0b1111 | 0b0011 = 0b1111
     * ......
     * .....
     * n = 0b1111 = 15
     * 
     * 2.这里的cap必须要减1，如果不减，并且如果传入的cap为16，那么算出来的值为32
     * 
     * 3.这个方法就是为了把最高位1的后面都变为1
     * 0001 1101 1100 -> 0001 1111 1111 -> +1 -> 0010 1111 1111
     */
    static final int tableSizeFor(int cap) {
        int n = cap - 1;
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
```

## 2.3 put方法分析

```java
    /**
     * @param key key with which the specified value is to be associated
     * @param value value to be associated with the specified key
     * @return the previous value associated with key, or
     *         null if there was no mapping for key.
     *         (A null return can also indicate that the map
     *         previously associated null with key.)
     *         返回先前key对应的value值（如果value为null，也返回null），如果先前不存在这个key，那么返回的就是null；
     */
    public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
        //把需要保存的键值对的键进行hash()运算, 在运行putVal()方法
    }
    /
    * 在往haspmap中插入一个元素的时候，由元素的hashcode经过一个扰动函数之后再与table的长度进行与运算才找到插入位置，下面的这个hash()方法就是所谓的扰动函数
     * 作用：让key的hashCode值的高16位参与运算,hash()方法返回的值的低十六位是有hashCode的高低16位共同的特征的
     * 举例
     * hashCode = 0b 0010 0101 1010 1100  0011 1111 0010 1110
     * 
     *     0b 0010 0101 1010 1100  0011 1111 0010 1110  ^ 
     *     0b 0000 0000 0000 0000  0010 0101 1010 1100 
     *     0b 0010 0101 1010 1100  0001 1010 1000 0010
        ^异或运算  不同为1 相同为0
     */
    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
```



```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        // tab表示当前hashmap的散列表
        // p表示散列表的元素
        // n表示散列表数组的长度
        // i表示路由寻址结果
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        
        // 延迟初始化逻辑，第一次调用putval()方法的时候才进行初始化hashmap中最耗内存的talbe
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        
        // 1.最简单的一种情况，寻找到的桶位，刚好是null，这个时候直接构建Node节点放进去就行了
    	//即根据要放入的key获取到的hsah值经过路由寻址计算之后,获取到的下标中没有数据元素
        if ((p = tab[i = (n - 1) & hash]) == null)
            
            tab[i] = newNode(hash, key, value, null);
        else {
            // e，如果key不为null，并且找到了当前要插入的key一致的node元素，就保存在e中
            // k表示一个临时的key
            Node<K,V> e; K k;
            
            // 2.表示该桶位中的第一个元素的key与你当前插入的node元素的key一致，表示后序要进行替换操作
            // hashcode相同 key也相同就直接进行覆盖操作
            if (p.hash == hash &&
                    ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            
            // 3.插入k-v时候如果该桶位链表已经树化了的情况
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            
            // 4.当前捅位依旧是一个链表的情况下
            else {
                for (int binCount = 0; ; ++binCount) {
                    // 4.1 迭代到最后一个元素了也没有找到要插入的key一致的node
                    if ((e = p.next) == null) {
                        //就直接把该元素放入到该链表的最后边
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
							//如果当前链表的长度达到树化标准就进行树化操作
                            treeifyBin(tab, hash);
                        break;
                    }

                    // 4.1 找到了与要插入的元素的node元素相同的key的情况下 就把该元素的值进行覆盖替换操作
                    if (e.hash == hash &&
                            ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            
            // 如果找到了与要插入的key一致的node元素，那么进行替换
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        // nodeCount用来记录散列表table结构的修改次数，替换Node元素的value不算
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```





## 2.4 resize方法分析

当在table长度位16中的元素移到table长度位32的table中的时候；我们可以知道，原来在15这个槽位的元素的hash()值的后四位一定是1111（因为跟1111即table长度-1  进行与运算得到了1111）。所以所以当table长度变为32的时候，原来在15这个槽位的元素要么还在15这个槽位，要么在31这个操作（因为原来15这个槽位的元素后五位一定是11111或者01111，跟 11111即table新长度-1 进行与运算一定得到 01111或者11111）

![1601638246856](https://gitee.com/gu_chun_bo/picture/raw/master/image/20201002193049-143709.png)

```java
/**
 * 对散列表进行初始化或者扩容。
 * 如果散列表为null，则对散列表进行初始化
 * 如果对散列表扩容，因为每次扩容都是翻倍，与原来计算（n-1）&hash的结果相比，节点要么就在原来的位置，要么就被分配到“原位置+旧容量”这个位置。
 */
    final Node<K,V>[] resize() {
        //oldTab :引用扩容之前的散列表
        Node<K,V>[] oldTab = table;
        
        // oldCap表示扩容之前table数组的长度
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        
        // oldThr表示本次扩容之前的阈值，触发本次扩容操作的阈值
        int oldThr = threshold;
        
        // newCap: 表示扩容之后table数组的大小； 
        // newThr: 表示扩容之后，下次出发扩容的条件
        int newCap, newThr = 0;
        //===================给newCap和newThr赋值start=============================
        
        // oldCap大于零，说明之前已经初始化过了（hashmap中的散列表不是null），要进行正常的扩容操作
        if (oldCap > 0) {
            // 已经最大值了，不再扩容了 且设置条件为int型数据的最大值
            if (oldCap >= MAXIMUM_CAPACITY) {
                threshold = Integer.MAX_VALUE;
                return oldTab;
            }
            // （1）进行翻倍扩容(假如旧的oldCap为8， < DEFAULT_INITIAL_CAPACITY，那么此条件不成立newThr将不会赋值)
			// oldCap左移一位 实现数值翻倍，并且赋值给newCap, newCap小于数组最大限制,且扩容之前的阈值>=16
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                    oldCap >= DEFAULT_INITIAL_CAPACITY) //数组默认长度为16DEFAULT_INITIAL_CAPACITY = 1 << 4  ;
                newThr = oldThr << 1; // double threshold
        }
        // （2）
        // oldCap == 0（说明hashmap中的散列表是null）且oldThr > 0 ；下面几种情况都会出现oldCap == 0,oldThr > 0
        // 1.public HashMap(int initialCapacity);
        // 2.public HashMap(Map<? extends K, ? extends V> m);并且这个map有数据
        // 3.public HashMap(int initialCapacity, float loadFactor);
        else if (oldThr > 0) // initial capacity was placed in threshold
            newCap = oldThr;
        
        // public HashMap();  oldCap == 0, oldThr == 0
        else {               // zero initial threshold signifies using defaults
            newCap = DEFAULT_INITIAL_CAPACITY;//数组默认长度为16:DEFAULT_INITIAL_CAPACITY = 1 << 4 
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);//LOAD_FACTOR 默认为0.75 *16==12
        }

        // newThr为0 通过newCap和loadFactor计算出一个newThr 对应上面（1）不成立或者（2）成立的情况
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                    (int)ft : Integer.MAX_VALUE);
        }
        //===================给newCap和newThr赋值end=============================
        threshold = newThr;
        
        //创建出一个更长更大的数组
        @SuppressWarnings({"rawtypes","unchecked"})
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
        table = newTab;
        //oldTab!=null 说明hashMap在扩容前table不为null 即hashMap不为空
        if (oldTab != null) {
            for (int j = 0; j < oldCap; ++j) {
                //循环中的当前节点
                Node<K,V> e;
                
                // 说明当前桶位中有数据,但是数据是单个数据,还是链表还是红黑树,是不确定的
                if ((e = oldTab[j]) != null) {
                    // 将对应的桶位指向null，方便jvm回收
                    oldTab[j] = null;

                    // 1.如果只有一个节点 node节点.next为空 就表示就只有一个node节点
                    // 当前桶位只有一个数据的情况下,直接使用路由寻址算法,算出当前元素存放在新的数组中的位置
                    if (e.next == null)
                        newTab[e.hash & (newCap - 1)] = e;

                    // 2.当前桶位已经树化了
                    else if (e instanceof TreeNode)
                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);

                    // 3.当前桶位是链表
                    else { // preserve order

                        // 低位链表：存放在扩容之后的数组下标的位置，与当前数组下标位置一致的元素
                        // 高位链表：存放在扩容之后的数组下标的位置为当前数组下标位置+ 扩容之前数组长度的元素
                        Node<K,V> loHead = null, loTail = null;
                        Node<K,V> hiHead = null, hiTail = null;

                        Node<K,V> next;
                        do {
                            next = e.next;

                            // 比如e.hash只能为两种可能  ......1 1111 或者...... 0 1111 ， oldCap 为 10000
                            //在把当前节点的hash值与桶位hash进行& 运算,就可以算出 这个节点是放在原数组中,还是扩容数组中
                            if ((e.hash & oldCap) == 0) {//如果是0 就把当前元素放在低位链表
                                if (loTail == null)
                                    loHead = e;     //如果当前链表没有数据 为null 就把当前节点放在头结点位置
                                else
                                    loTail.next = e;//如果当前链表有数据,不为null 就把当前节点直接放在链表后边
                                loTail = e;
                            }
                            else {					//如果记性路由寻址计算后,不为0的情况下,就放入到新产生的扩容数组之中
                                if (hiTail == null)
                                    hiHead = e;		//如果当前链表没有数据 为null 就把当前节点放在头结点位置
                                else
                                    hiTail.next = e;//如果当前链表有数据,不为null 就把当前节点直接放在链表后边
                                hiTail = e;
                            }
                        } while ((e = next) != null);

                        //运行上边的代码之后,就把链表中的数据分为了多条链表,如果低链表中有数据,就把低链表尾部设置为空,再把新数组设置为低链表的头部
                        // 如果低位链表有数据
                        if (loTail != null) {
                            loTail.next = null;
                            newTab[j] = loHead;
                        }
                        // 如果高位链表有数据  和低链表操作一样,也是把高链表尾部设置为null 把新数组位置设置为高链表的头部
                        if (hiTail != null) {
                            hiTail.next = null;
                            newTab[j + oldCap] = hiHead;//数组位置为初始位置+老的数组长度  例如当前为index=15的位置,新位置就为15+16=31
                        }
                    }
                }
            }
        }
        return newTab;
    }
```

## 2.5 get方法分析

```java
   public V get(Object key) {
        Node<K,V> e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }

   final Node<K,V> getNode(int hash, Object key) {
        // tab：引用当前hashmap的table
        // Node first：桶位中的头元素
        // Node e：是临时Node元素
        // n：table的长度
        // k：是key的临时变量
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
       
        // 1.如果哈希表为不为空，就进行下边的操作,或key对应的桶为空，直接返回null
        if ((tab = table) != null && (n = tab.length) > 0 &&
                (first = tab[(n - 1) & hash]) != null) {
            
            // 2.这个桶的头元素就是想要找的
            if (first.hash == hash && // always check first node
                    ((k = first.key) == key || (key != null && key.equals(k))))
                return first;
            
            // 说明当前桶位不止一个元素，可能是链表，也可能是红黑树
            if ((e = first.next) != null) {
                // 3.桶位已经树化了
                if (first instanceof TreeNode)
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                
                // 4.桶位依旧是链表
                do {
                    if (e.hash == hash &&
                            ((k = e.key) == key || (key != null && key.equals(k))))
                        //循环遍历判断当前桶位内的节点的hash是否是和需要查找节点是否相同 key的值是否相同,如果相同就返回当前节点
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;//hashmap为空,就直接返回null
    }
```

## 2.6 remove方法分析

```java
    public V remove(Object key) {
        Node<K,V> e;
        return (e = removeNode(hash(key), key, null, false, true)) == null ?null : e.value;
		//进行remov()方法,进行返回,调用removeNode()方法返回的是null 那就返回null 如果不为null 就返回节点的value值
    }    

    final Node<K,V> removeNode(int hash, Object key, Object value,
                               boolean matchValue, boolean movable) {
        // tab：引用当前hashmap的散列表
        // Node p：当前的node元素
        // n：当前的散列表数组长度
        // index：表示寻址结果桶位数组的index下标位置
        Node<K,V>[] tab; Node<K,V> p; int n, index;

        // 1.如果数组table为空或key映射到的桶为空，返回null。
        if ((tab = table) != null && (n = tab.length) > 0 &&
                (p = tab[index = (n - 1) & hash]) != null) {//根据路由寻址找到具体的桶位下标 并把桶位头元素赋值为p
            //说明路由的桶位是有数据的,需要进行查找操作并且进行删除操作

            // node：查找到的结果
            // e：当前Node的下一个元素
            Node<K,V> node = null, e; K k; V v;

            // 2.数组桶位的头元素就是我们要找的
            if (p.hash == hash &&
                    ((k = p.key) == key || (key != null && key.equals(k))))
                node = p;

            else if ((e = p.next) != null) {//说明当前桶位不止一个元素,可能是链表也可能是红黑树
                
                // 3.桶位已经树化了
                if (p instanceof TreeNode)
                    node = ((TreeNode<K,V>)p).getTreeNode(hash, key);
                
                // 4.桶位依旧是链表
                else {
                    do {
                        if (e.hash == hash &&
                                ((k = e.key) == key ||
                                        (key != null && key.equals(k)))) {
                            //循环遍历当前桶位中所有的节点,然后对节点的hash值和key值进行比较,如果找到对应的 就返回当前节点
                            node = e;
                            break;
                        }
                        p = e;  //每次p都会被赋值为当前节点,直到当前节点是p的下一个节点
                    } while ((e = e.next) != null);
                }
            }

            // 上边就进行一个查找操作,下边进行删除操作
            // 如果node不为null，说明按照key查找到想要删除的数据了
            if (node != null && (!matchValue || (v = node.value) == value ||
                    (value != null && value.equals(v)))) {
                
                // 桶位是树结构，删除节点
                if (node instanceof TreeNode)
                    ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
                
                // 查找的元素就是当前桶位的第一个元素,那么就直接删除当前桶的第一个元素
                else if (node == p)
                    tab[index] = node.next;
                
                //桶位是链表结构时 进行的删除操作
                else
                    p.next = node.next;
                //上边进行查找操作之后,桶位第一个元素p.next-->node  所以这里直接把指针p.next-->node.next,就相当于把node删除了
                //因为上边进行查找的时候,如果是链表结构,就进行对p的重新赋值,做到了p一直指向寻找的节点
                ++modCount;
                --size;
                afterNodeRemoval(node);
                return node;           //执行结果返回node节点
            }
        }
        return null;
    }

```





## 2.7 replace方法分析



```java
	HashMap<Integer, String> sites = new HashMap<>();   
	sites.put(1, "Google");
    sites.put(2, "Runoob");

	@Override
	//三个参数的replace()方法 
	//sites.replace(2, "Runoob", "Zhihu"); //把k为2 的值Runoob 替换为Zhihu
	//sites.replace(2, "Weibo", "Zhihu");  //把k为2 的值Weibo  替换为Zhihu 这种情况是HashMap中不存在传入k-v的情况	
	//运行中会有一个getNode()方法 传入的是replace()中的key的hash值 key  返回的是key对应的节点
    public boolean replace(K key, V oldValue, V newValue) {
        //传入需要传入的k-v 以及新的value值
        //Node e:临时Node e
        Node<K,V> e; V v;
        if ((e = getNode(hash(key), key)) != null &&	//使用getNode()方法根据key的hash值获取到对应的节点 并赋值给Node节点 e
                ((v = e.value) == oldValue || (v != null && v.equals(oldValue)))) {//比对当前节点e的value值是否和旧值相同,相同就运行
            e.value = newValue;//HashMap中含有传入的K-V 就直接把k对应的value替换为传入的新的value值
            afterNodeAccess(e);
            return true;
        }
        return false;//判断传入的key 对应的value值和hashMap中不同(即:HashMap中不包含传入的K-V),所以直接返回false
    }

    @Override
	//此处是两个参数的replace()方法,只需要传入key 和新的value值
    public V replace(K key, V value) {
        Node<K,V> e;
        if ((e = getNode(hash(key), key)) != null) {//运行getNode()后如果不为null 即存在对应的k 就替换k对应的value
            V oldValue = e.value;
            e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
        return null;
    }

	final HashMap.Node<K,V> getNode(int hash, Object key) {
        // tab：引用当前hashmap的table
        // Node first：桶位中的头元素
        // Node e：是临时Node元素
        // n：table的长度
        // k：是key的临时变量
        HashMap.Node<K,V>[] tab; HashMap.Node<K,V> first, e; int n; K k;
        //查看数据需要满足一下条件
 
        //3)通过hash计算出该元素在数组中存放位置的索引,而且该索引处数据不为空null
        if ((tab = table) != null && (n = tab.length) > 0 &&
                (first = tab[(n - 1) & hash]) != null) {
            
            //判断该数组索引位置处第一个是否为我们要找的元素 判断条件需要满足hash 和 key 相同
            if (first.hash == hash && // always check first node
                    ((k = first.key) == key || (key != null && key.equals(k))))
                return first;//如果第一个就是我们要找的,直接返回即可
            
            //如果第一个不是,我们需要循环遍历,然后找数据
            if ((e = first.next) != null) {
                
                //桶中的链表转换为红黑树情况
                if (first instanceof HashMap.TreeNode)
                    //那我们需要调用红黑树的方法查找节点
                    return ((HashMap.TreeNode<K,V>)first).getTreeNode(hash, key);
                
                //桶中的结构依然是链表的情况下
                do {
                    //循环判断当前节点的hash和key是否和传入的相同
                    if (e.hash == hash &&
                            ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;	//如果hash key都相同 就返回当前节点
                } while ((e = e.next) != null);//更新e为下一个
            }
        }
        //没找到返回Null
        return null;
    }

```



## 2.8 其它常用方法

### isEmpty()

```java
/**
 * 如果map中没有键值对映射，返回true
 * 
 * @return <如果map中没有键值对映射，返回true
 */
public boolean isEmpty() {
    return size == 0;
}
```

### putMapEntries()

```java
    final void putMapEntries(Map<? extends K, ? extends V> m, boolean evict) {
        int s = m.size();
        if (s > 0) {
            // table为null，代表这里使用HashMap(Map<? extends K, ? extends V> m)构造函数 或者其它方式实例化hashmap但是还没往里面添加过元素
            if (table == null) { // pre-size
                //前面讲到，initial capacity*load factor就是当前hashMap允许的最大元素数目。那么不难理解，s/loadFactor+1即为应该初始化的容量。
                float ft = ((float)s / loadFactor) + 1.0F;
                int t = ((ft < (float)MAXIMUM_CAPACITY) ?
                        (int)ft : MAXIMUM_CAPACITY);
                if (t > threshold)
                    threshold = tableSizeFor(t);
            }
            //table已经初始化，并且map的大小大于临界值
            else if (s > threshold)
                //扩容处理
                resize();
            //将map中所有键值对添加到hashMap中
            for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {
                K key = e.getKey();
                V value = e.getValue();
                putVal(hash(key), key, value, false, evict);
            }
        }
    }
```

### putAll()

```java
/**
 * 将参数map中的所有键值对映射插入到hashMap中，如果有碰撞，则覆盖value。
 * @param m 参数map
 * @throws NullPointerException 如果map为null
 */
public void putAll(Map<? extends K, ? extends V> m) {
    putMapEntries(m, true);
}
```

### clear()

```java
/**
 * 删除map中所有的键值对
 */
public void clear() {
    Node<K,V>[] tab;
    modCount++;
    if ((tab = table) != null && size > 0) {
        size = 0;
        for (int i = 0; i < tab.length; ++i)
            tab[i] = null;
    }
}
```

### containsValue( Object value)

```java
/**
 * 如果hashMap中的键值对有一对或多对的value为参数value，返回true
 *
 * @param value 参数value
 * @return 如果hashMap中的键值对有一对或多对的value为参数value，返回true
 */
public boolean containsValue(Object value) {
    Node<K,V>[] tab; V v;
    //
    if ((tab = table) != null && size > 0) {
        //遍历数组table
        for (int i = 0; i < tab.length; ++i) {
            //遍历桶中的node
            for (Node<K,V> e = tab[i]; e != null; e = e.next) {
                if ((v = e.value) == value ||
                    (value != null && value.equals(v)))
                    return true;
            }
        }
    }
    return false;
}
```

# 3.参考

1. [视频](https://www.bilibili.com/video/BV1LJ411W7dP)
2. [3y](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247484139&idx=1&sn=bb73ac07081edabeaa199d973c3cc2b0&chksm=ebd743eadca0cafc532f298b6ab98b08205e87e37af6a6a2d33f5f2acaae245057fa01bd93f4&scene=21#wechat_redirect)
3. [csdn](https://blog.csdn.net/panweiwei1994/article/details/77244920)





